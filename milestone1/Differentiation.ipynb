{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/4NRDvIHdHgrH7q6/Za3s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"RU18tJgXzEIu","executionInfo":{"status":"ok","timestamp":1719829990741,"user_tz":-540,"elapsed":342,"user":{"displayName":"이주창","userId":"11438547241459994037"}}},"outputs":[],"source":["import torch\n","\n","x = torch.ones(5)  # input tensor\n","y = torch.zeros(3)  # expected output\n","w = torch.randn(5, 3, requires_grad=True)\n","b = torch.randn(3, requires_grad=True)\n","# z = x^T w + b\n","z = torch.matmul(x, w)+b\n","loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"]},{"cell_type":"code","source":["print(f\"Gradient function for z = {z.grad_fn}\")\n","print(f\"Gradient function for loss = {loss.grad_fn}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DKxIZsuzHcL","executionInfo":{"status":"ok","timestamp":1719829994483,"user_tz":-540,"elapsed":364,"user":{"displayName":"이주창","userId":"11438547241459994037"}},"outputId":"70ed1729-2098-4405-ce21-2090a7c9a17f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient function for z = <AddBackward0 object at 0x7981d3129cf0>\n","Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7981d312a350>\n"]}]},{"cell_type":"code","source":["# backward pass\n","loss.backward()\n","print(w.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47YLfdWFzI1h","executionInfo":{"status":"ok","timestamp":1719829995886,"user_tz":-540,"elapsed":2,"user":{"displayName":"이주창","userId":"11438547241459994037"}},"outputId":"a3628bc4-d92a-4002-836e-729ef608688a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0118, 0.0279, 0.3183],\n","        [0.0118, 0.0279, 0.3183],\n","        [0.0118, 0.0279, 0.3183],\n","        [0.0118, 0.0279, 0.3183],\n","        [0.0118, 0.0279, 0.3183]])\n","tensor([0.0118, 0.0279, 0.3183])\n"]}]},{"cell_type":"code","source":["z = torch.matmul(x, w)+b\n","print(z.requires_grad)\n","\n","# no_grad stops gradient computation\n","with torch.no_grad():\n","    z = torch.matmul(x, w)+b\n","print(z.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjAPNoMKzKXh","executionInfo":{"status":"ok","timestamp":1719830132983,"user_tz":-540,"elapsed":553,"user":{"displayName":"이주창","userId":"11438547241459994037"}},"outputId":"dc18cdd9-6394-4e83-cd69-915088319bfd"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"code","source":["z = torch.matmul(x, w)+b\n","# detach stops gradient calculation from specific layer?\n","# useful for model freezing?\n","z_det = z.detach()\n","print(z_det.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t97j94z7zLus","executionInfo":{"status":"ok","timestamp":1719830172022,"user_tz":-540,"elapsed":2,"user":{"displayName":"이주창","userId":"11438547241459994037"}},"outputId":"d13c040c-31e3-4b9f-c419-4719a700575e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["inp = torch.eye(4, 5, requires_grad=True)\n","print(inp)\n","out = (inp+1).pow(2).t()\n","print(out)\n","out.backward(torch.ones_like(out), retain_graph=True)\n","print(f\"First call\\n{inp.grad}\")\n","out.backward(torch.ones_like(out), retain_graph=True)\n","print(f\"\\nSecond call\\n{inp.grad}\")\n","inp.grad.zero_()\n","out.backward(torch.ones_like(out), retain_graph=True)\n","print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3enS0bVSzO9X","executionInfo":{"status":"ok","timestamp":1719830506541,"user_tz":-540,"elapsed":464,"user":{"displayName":"이주창","userId":"11438547241459994037"}},"outputId":"8c0769b8-3a80-4579-fed1-f2dbb16a1a53"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0.]], requires_grad=True)\n","tensor([[4., 1., 1., 1.],\n","        [1., 4., 1., 1.],\n","        [1., 1., 4., 1.],\n","        [1., 1., 1., 4.],\n","        [1., 1., 1., 1.]], grad_fn=<TBackward0>)\n","First call\n","tensor([[4., 2., 2., 2., 2.],\n","        [2., 4., 2., 2., 2.],\n","        [2., 2., 4., 2., 2.],\n","        [2., 2., 2., 4., 2.]])\n","\n","Second call\n","tensor([[8., 4., 4., 4., 4.],\n","        [4., 8., 4., 4., 4.],\n","        [4., 4., 8., 4., 4.],\n","        [4., 4., 4., 8., 4.]])\n","\n","Call after zeroing gradients\n","tensor([[4., 2., 2., 2., 2.],\n","        [2., 4., 2., 2., 2.],\n","        [2., 2., 4., 2., 2.],\n","        [2., 2., 2., 4., 2.]])\n"]}]}]}